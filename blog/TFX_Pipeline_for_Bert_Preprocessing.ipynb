{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS82Qjx4MDdT",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright &copy; 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqQLjcldMDdU",
        "colab_type": "text"
      },
      "source": [
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58yt61n9MDdU",
        "colab_type": "text"
      },
      "source": [
        "# Example TFX Pipeline demonstrating the usage of BERT\n",
        "\n",
        "This pipeline demonstrates data preprocessing, training, and export of a sentiment model based on the BERT model. Details about this pipeline can be found on the TensorFlow Blog post [Part 1: Fast, scalable and accurate NLP: Why TFX is a perfect match for deploying BERT](https://blog.tensorflow.org/2020/03/part-1-fast-scalable-and-accurate-nlp-tensorflow-deploying-bert.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21U7Zkw0P8bT",
        "colab_type": "text"
      },
      "source": [
        "Last updated November 20th, 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKw0EZddMDdX",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" width=\"100%\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/workshops/blob/master/blog/TFX_Pipeline_for_Bert_Preprocessing.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/workshops/blob/master/blog/TFX_Pipeline_for_Bert_Preprocessing.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o18JmOsdRTEw",
        "colab_type": "text"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "Instead of converting the input to a tranformer model into token ids on the client side, the model exported from this pipeline will allow the conversion on the server side.\n",
        "\n",
        "The pipeline takes advantage of the broad TensorFlow Eco system, including:\n",
        "* Loading the IMDB dataset via **TensorFlow Datasets**\n",
        "* Loading a pre-trained model via **tf.hub**\n",
        "* Manipulating the raw input data with **tf.text**\n",
        "* Building a simple model architecture with **Keras**\n",
        "* Composing the model pipeline with **TensorFlow Extended**, e.g. TensorFlow Transform, TensorFlow Data Validation and then consuming the tf.Keras model with the latest Trainer component from TFX\n",
        "\n",
        "The structure of the overall pipeline follows the [TFX Taxi Cab example](https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/components.ipynb) \n",
        "\n",
        "### Outline\n",
        "\n",
        "* Install Required Packages\n",
        "* Load the training data set\n",
        "* Create the TFX Pipeline\n",
        "* Export the trained Model\n",
        "* Test the exported Model\n",
        "\n",
        "**Non-Colab users** \n",
        "\n",
        "This notebook was written to run in Google Colab environments. But they can run in any Jupyter environment. In that case, update the file and directory path and install TensorFlow>=2.2.0 manually.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rinax0YJ_otk",
        "colab_type": "text"
      },
      "source": [
        "# Project Setup\n",
        "\n",
        "## Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjjgiv0bM0hi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "c96614e1-35e7-4e38-abdd-e2e965887ef8"
      },
      "source": [
        "try:\n",
        "    import colab\n",
        "    !pip install --upgrade pip\n",
        "except:\n",
        "    pass\n",
        "\n",
        "!pip install -Uq tfx==0.25.0\n",
        "!pip install -Uq tensorflow_datasets==4.1.0\n",
        "!pip install -Uq tensorflow-text  # The tf-text version needs to match the tf version\n",
        "\n",
        "print(\"Restart your runtime enable after installing the packages\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rqjoMKeMxWq",
        "colab_type": "text"
      },
      "source": [
        "## Restart the Runtime Engine\n",
        "\n",
        "**Note** \n",
        "You need to restart the Colab Runtime Engine after installing the required Python packages. Restart your Colab Kernel through the Colab Menu (Menu > Runtime > Restart runtime...) or execute the following code snippet.\n",
        "\n",
        "![Restart of the Colab Runtime Engine](https://drive.google.com/uc?id=1xnjAy2sxIymKhydkqb0RKzgVK9rh3teH)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dk0MPs7MDdc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00fa10c4-7d27-41b2-cda4-fdb906640350"
      },
      "source": [
        "# Restart the Colab notebook programmatically\n",
        "\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQSFUNALhFG",
        "colab_type": "text"
      },
      "source": [
        "## Import relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oThi-x8xLlv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import pprint\n",
        "import re\n",
        "import tempfile\n",
        "from shutil import rmtree\n",
        "from typing import List, Dict, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_data_validation as tfdv\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow_transform as tft\n",
        "import tensorflow_transform.beam as tft_beam\n",
        "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
        "from tensorflow_transform.saved import saved_transform_io\n",
        "from tensorflow_transform.tf_metadata import (dataset_metadata, dataset_schema,\n",
        "                                              metadata_io, schema_utils)\n",
        "from tfx.components import (Evaluator, ExampleValidator, ImportExampleGen,\n",
        "                            ModelValidator, Pusher, ResolverNode, SchemaGen,\n",
        "                            StatisticsGen, Trainer, Transform)\n",
        "from tfx.components.base import executor_spec\n",
        "from tfx.components.trainer.executor import GenericExecutor\n",
        "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
        "from tfx.proto import evaluator_pb2, example_gen_pb2, pusher_pb2, trainer_pb2\n",
        "from tfx.types import Channel\n",
        "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
        "from tfx.utils.dsl_utils import external_input\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow_text as text\n",
        "\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import \\\n",
        "    InteractiveContext\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuKziu0W9o7O",
        "colab_type": "text"
      },
      "source": [
        "## Check GPU Availability\n",
        "\n",
        "Check if your Colab notebook is configured to use Graphical Processing Units (GPUs). If zero GPUs are available, check if the Colab notebook is configured to use GPUs (Menu > Runtime > Change Runtime Type).\n",
        "\n",
        "![Hardware Accelerator Settings](https://drive.google.com/uc?id=1qrihuuMtvzXJHiRV8M7RngbxFYipXKQx)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlvqWtr7R8eu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc2f36a7-96b0-444a-93ff-54d014fd6f12"
      },
      "source": [
        "num_gpus_available = len(tf.config.experimental.list_physical_devices('GPU'))\n",
        "print(\"Num GPUs Available: \", num_gpus_available)\n",
        "assert num_gpus_available > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4OMItPSLnDj",
        "colab_type": "text"
      },
      "source": [
        "## Download the IMDB Dataset from TensorFlow Datasets\n",
        "\n",
        "For our demo example, we are using the [IMDB data set](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) to train a sentiment model based on the pre-trained BERT model. The data set is provided through [TensorFlow Datasets](https://www.tensorflow.org/datasets). Our ML pipeline can read TFRecords, however it expects only TFRecord files in the data folder. That is the reason why we need to delete the additional files provided by TFDS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjWjnzPGKjIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3b1297e4-8bcb-49b2-aef5-cd8466084e48"
      },
      "source": [
        "!mkdir /content/tfds/\n",
        "\n",
        "def clean_before_download(base_data_dir):\n",
        "    rmtree(base_data_dir)\n",
        "    \n",
        "def delete_unnecessary_files(base_path):\n",
        "    counter = 0\n",
        "    file_list = [\"dataset_info.json\", \"label.labels.txt\", \"feature.json\"]\n",
        "\n",
        "    for f in file_list:\n",
        "        try:\n",
        "            os.remove(os.path.join(base_path, f))\n",
        "            counter += 1\n",
        "        except OSError:\n",
        "            pass\n",
        "\n",
        "    for f in glob.glob(base_path + \"imdb_reviews-unsupervised.*\"):\n",
        "        os.remove(f)\n",
        "        counter += 1\n",
        "    print(f\"Deleted {counter} files\")\n",
        "\n",
        "def get_dataset(name='imdb_reviews', version=\"1.0.0\"):\n",
        "\n",
        "    base_data_dir = \"/content/tfds/\"\n",
        "    config=\"plain_text\"\n",
        "    version=\"1.0.0\"\n",
        "\n",
        "    clean_before_download(base_data_dir)\n",
        "    tfds.disable_progress_bar()\n",
        "    builder = tfds.text.IMDBReviews(data_dir=base_data_dir, \n",
        "                                    config=config, \n",
        "                                    version=version)\n",
        "    download_config = tfds.download.DownloadConfig(\n",
        "        download_mode=tfds.GenerateMode.FORCE_REDOWNLOAD)\n",
        "    builder.download_and_prepare(download_config=download_config)\n",
        "\n",
        "    base_tfrecords_filename = os.path.join(base_data_dir, \"imdb_reviews\", config, version, \"\")\n",
        "    train_tfrecords_filename = base_tfrecords_filename + \"imdb_reviews-train*\"\n",
        "    test_tfrecords_filename = base_tfrecords_filename + \"imdb_reviews-test*\"\n",
        "    label_filename = os.path.join(base_tfrecords_filename, \"label.labels.txt\")\n",
        "    labels = [label.rstrip('\\n') for label in open(label_filename)]\n",
        "    delete_unnecessary_files(base_tfrecords_filename)\n",
        "    return (train_tfrecords_filename, test_tfrecords_filename), labels\n",
        "\n",
        "tfrecords_filenames, labels = get_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDtPNfOwriT8",
        "colab_type": "text"
      },
      "source": [
        "## Helper function to load the BERT model as Keras layer\n",
        "\n",
        "In our pipeline components, we are reusing the BERT Layer from tf.hub in two places\n",
        "* in the model architecture when we define our Keras model\n",
        "* in our preprocessing function when we extract the BERT settings (casing and vocab file path) to reuse the settings during the tokenization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tre_oQu0rlrU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d225e31-af10-4e2d-9e43-6e777458e610"
      },
      "source": [
        "%%skip_for_export\n",
        "%%writefile bert.py\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "BERT_TFHUB_URL = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\"\n",
        "\n",
        "def load_bert_layer(model_url=BERT_TFHUB_URL):\n",
        "    # Load the pre-trained BERT model as layer in Keras\n",
        "    bert_layer = hub.KerasLayer(\n",
        "        handle=model_url,\n",
        "        trainable=False)\n",
        "    return bert_layer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-5QGnm_lFJD",
        "colab_type": "text"
      },
      "source": [
        "# TFX Pipeline\n",
        "\n",
        "The TensorFlow Extended Pipeline is more or less following the example setup shown here. We'll only note deviations from the original setup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arPCEBYEFqEr",
        "colab_type": "text"
      },
      "source": [
        "## Initializing the Interactive TFX Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBO0T3D5kkOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61b5278a-343d-4119-c1f9-de45b3f80290"
      },
      "source": [
        "context = InteractiveContext()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo2Q-c_ynL2x",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8GqUHwAKm6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "76832894-21e7-47d5-f6e1-39207b5bc9b8"
      },
      "source": [
        "output = example_gen_pb2.Output(\n",
        "             split_config=example_gen_pb2.SplitConfig(splits=[\n",
        "                 example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=45),\n",
        "                 example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=5)\n",
        "             ]))\n",
        "# Load the data from our prepared TFDS folder\n",
        "example_gen = ImportExampleGen(input=\"/content/tfds/imdb_reviews/plain_text/1.0.0\", \n",
        "                               output_config=output)\n",
        "\n",
        "context.run(example_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu2ejZTWK-E5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4b6277f7-1452-49ff-ed1c-336e68a5e473"
      },
      "source": [
        "%%skip_for_export\n",
        "\n",
        "for artifact in example_gen.outputs['examples'].get():\n",
        "    print(artifact.uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE9VL-pmF6L_",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow Data Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EglytaKVLQzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "outputId": "2e4478b2-e649-4ca8-b712-04802fda1607"
      },
      "source": [
        "%%skip_for_export\n",
        "\n",
        "statistics_gen = StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)\n",
        "\n",
        "context.show(statistics_gen.outputs['statistics'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBYoEPhBeQUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "e6257bb2-1577-4b17-d91f-fa4f984ddf53"
      },
      "source": [
        "%%skip_for_export\n",
        "\n",
        "schema_gen = SchemaGen(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    infer_feature_shape=True)\n",
        "context.run(schema_gen)\n",
        "\n",
        "context.show(schema_gen.outputs['schema'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl2gkqytjr0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "fe10c0e2-b532-4f7d-e55b-20036f2a5946"
      },
      "source": [
        "%%skip_for_export\n",
        "\n",
        "# check the data schema for the type of input tensors\n",
        "tfdv.load_schema_text(schema_gen.outputs['schema'].get()[0].uri + \"/schema.pbtxt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWRswNYye6So",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "a5e1f8c4-6367-4837-ba80-65207c780e95"
      },
      "source": [
        "%%skip_for_export\n",
        "\n",
        "example_validator = ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator)\n",
        "\n",
        "context.show(example_validator.outputs['anomalies'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zqjzTx2s5HS",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow Transform\n",
        "\n",
        "This is where we perform the BERT processing. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K91irJq7q6vC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "341c33a6-80b2-4184-f58c-606a8cb77f91"
      },
      "source": [
        "%%skip_for_export\n",
        "%%writefile transform.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as text\n",
        "\n",
        "from bert import load_bert_layer\n",
        "\n",
        "MAX_SEQ_LEN = 512  # max number is 512\n",
        "do_lower_case = load_bert_layer().resolved_object.do_lower_case.numpy()\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "    \"\"\"Preprocess input column of text into transformed columns of.\n",
        "        * input token ids\n",
        "        * input mask\n",
        "        * input type ids\n",
        "    \"\"\"\n",
        "\n",
        "    CLS_ID = tf.constant(101, dtype=tf.int64)\n",
        "    SEP_ID = tf.constant(102, dtype=tf.int64)\n",
        "    PAD_ID = tf.constant(0, dtype=tf.int64)\n",
        "\n",
        "    vocab_file_path = load_bert_layer().resolved_object.vocab_file.asset_path\n",
        "    \n",
        "    bert_tokenizer = text.BertTokenizer(vocab_lookup_table=vocab_file_path, \n",
        "                                        token_out_type=tf.int64, \n",
        "                                        lower_case=do_lower_case) \n",
        "    \n",
        "    def tokenize_text(text, sequence_length=MAX_SEQ_LEN):\n",
        "        \"\"\"\n",
        "        Perform the BERT preprocessing from text -> input token ids\n",
        "        \"\"\"\n",
        "\n",
        "        # convert text into token ids\n",
        "        tokens = bert_tokenizer.tokenize(text)\n",
        "        \n",
        "        # flatten the output ragged tensors \n",
        "        tokens = tokens.merge_dims(1, 2)[:, :sequence_length]\n",
        "        \n",
        "        # Add start and end token ids to the id sequence\n",
        "        start_tokens = tf.fill([tf.shape(text)[0], 1], CLS_ID)\n",
        "        end_tokens = tf.fill([tf.shape(text)[0], 1], SEP_ID)\n",
        "        tokens = tokens[:, :sequence_length - 2]\n",
        "        tokens = tf.concat([start_tokens, tokens, end_tokens], axis=1)\n",
        "\n",
        "        # truncate sequences greater than MAX_SEQ_LEN\n",
        "        tokens = tokens[:, :sequence_length]\n",
        "\n",
        "        # pad shorter sequences with the pad token id\n",
        "        tokens = tokens.to_tensor(default_value=PAD_ID)\n",
        "        pad = sequence_length - tf.shape(tokens)[1]\n",
        "        tokens = tf.pad(tokens, [[0, 0], [0, pad]], constant_values=PAD_ID)\n",
        "\n",
        "        # and finally reshape the word token ids to fit the output \n",
        "        # data structure of TFT  \n",
        "        return tf.reshape(tokens, [-1, sequence_length])\n",
        "\n",
        "    def preprocess_bert_input(text):\n",
        "        \"\"\"\n",
        "        Convert input text into the input_word_ids, input_mask, input_type_ids\n",
        "        \"\"\"\n",
        "        input_word_ids = tokenize_text(text)\n",
        "        input_mask = tf.cast(input_word_ids > 0, tf.int64)\n",
        "        input_mask = tf.reshape(input_mask, [-1, MAX_SEQ_LEN])\n",
        "        \n",
        "        zeros_dims = tf.stack(tf.shape(input_mask))\n",
        "        input_type_ids = tf.fill(zeros_dims, 0)\n",
        "        input_type_ids = tf.cast(input_type_ids, tf.int64)\n",
        "\n",
        "        return (\n",
        "            input_word_ids, \n",
        "            input_mask,\n",
        "            input_type_ids\n",
        "        )\n",
        "\n",
        "    input_word_ids, input_mask, input_type_ids = \\\n",
        "        preprocess_bert_input(tf.squeeze(inputs['text'], axis=1))\n",
        "\n",
        "    return {\n",
        "        'input_word_ids': input_word_ids,\n",
        "        'input_mask': input_mask,\n",
        "        'input_type_ids': input_type_ids,\n",
        "        'label': inputs['label']\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz5cevHYrR6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e63620a1-78d0-44c0-9afb-39bb30cf8488"
      },
      "source": [
        "transform = Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(\"transform.py\"))\n",
        "context.run(transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCcNJxWSKPPv",
        "colab_type": "text"
      },
      "source": [
        "#### Check the Output Data Struture of the TF Transform Operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcUEGmuhtmGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7ca3ef79-220f-48ca-c961-1861b3101e13"
      },
      "source": [
        "from tfx_bsl.coders.example_coder import ExampleToNumpyDict\n",
        "\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\n",
        "train_uri = transform.outputs['transformed_examples'].get()[0].uri\n",
        "\n",
        "print(train_uri)\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_folders = [os.path.join(train_uri, name) for name in os.listdir(train_uri)]\n",
        "tfrecord_filenames = []\n",
        "for tfrecord_folder in tfrecord_folders:\n",
        "    for name in os.listdir(tfrecord_folder):\n",
        "        tfrecord_filenames.append(os.path.join(tfrecord_folder, name))\n",
        "\n",
        "\n",
        "# Create a TFRecordDataset to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "for tfrecord in dataset.take(1):\n",
        "    serialized_example = tfrecord.numpy()\n",
        "    example = ExampleToNumpyDict(serialized_example)\n",
        "    pp.pprint(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdsXSG52kVoL",
        "colab_type": "text"
      },
      "source": [
        "## Training of the Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywjksr-vtxrX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f2082050-ce8b-43bd-9f3e-52781cae0f17"
      },
      "source": [
        "%%skip_for_export\n",
        "%%writefile trainer.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_model_analysis as tfma\n",
        "import tensorflow_transform as tft\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "from typing import Text\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_transform as tft\n",
        "from tfx.components.trainer.executor import TrainerFnArgs\n",
        "\n",
        "\n",
        "LABEL_KEY = 'label'\n",
        "BERT_TFHUB_URL = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\"\n",
        "\n",
        "\n",
        "def _gzip_reader_fn(filenames):\n",
        "    \"\"\"Small utility returning a record reader that can read gzip'ed files.\"\"\"\n",
        "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "\n",
        "def load_bert_layer(model_url=BERT_TFHUB_URL):\n",
        "    # Load the pre-trained BERT model as layer in Keras\n",
        "    bert_layer = hub.KerasLayer(\n",
        "        handle=model_url,\n",
        "        trainable=False)  # model can be fine-tuned \n",
        "    return bert_layer\n",
        "\n",
        "def get_model(tf_transform_output, max_seq_length=512):\n",
        "\n",
        "    # dynamically create inputs for all outputs of our transform graph\n",
        "    feature_spec = tf_transform_output.transformed_feature_spec()  \n",
        "    feature_spec.pop(LABEL_KEY)\n",
        "\n",
        "    inputs = {\n",
        "        key: tf.keras.layers.Input(shape=(max_seq_length), name=key, dtype=tf.int64)\n",
        "            for key in feature_spec.keys()\n",
        "    }\n",
        "\n",
        "    input_word_ids = tf.cast(inputs[\"input_word_ids\"], dtype=tf.int32)\n",
        "    input_mask = tf.cast(inputs[\"input_mask\"], dtype=tf.int32)\n",
        "    input_type_ids = tf.cast(inputs[\"input_type_ids\"], dtype=tf.int32)\n",
        "\n",
        "    bert_layer = load_bert_layer()\n",
        "    pooled_output, _ = bert_layer(\n",
        "        [input_word_ids, \n",
        "         input_mask, \n",
        "         input_type_ids\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # Add additional layers depending on your problem\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
        "    dense = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "    keras_model = tf.keras.Model(\n",
        "        inputs=[\n",
        "                inputs['input_word_ids'], \n",
        "                inputs['input_mask'], \n",
        "                inputs['input_type_ids']], \n",
        "        outputs=pred)\n",
        "    keras_model.compile(loss='binary_crossentropy', \n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
        "                        metrics=['accuracy']\n",
        "                        )\n",
        "    return keras_model\n",
        "\n",
        "\n",
        "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "    \"\"\"Returns a function that parses a serialized tf.Example and applies TFT.\"\"\"\n",
        "\n",
        "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "    @tf.function\n",
        "    def serve_tf_examples_fn(serialized_tf_examples):\n",
        "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
        "        feature_spec = tf_transform_output.raw_feature_spec()\n",
        "        feature_spec.pop(LABEL_KEY)\n",
        "        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
        "\n",
        "        transformed_features = model.tft_layer(parsed_features)\n",
        "\n",
        "        outputs = model(transformed_features)\n",
        "        return {'outputs': outputs}\n",
        "\n",
        "    return serve_tf_examples_fn\n",
        "\n",
        "def _input_fn(file_pattern: Text,\n",
        "              tf_transform_output: tft.TFTransformOutput,\n",
        "              batch_size: int = 32) -> tf.data.Dataset:\n",
        "    \"\"\"Generates features and label for tuning/training.\n",
        "\n",
        "    Args:\n",
        "      file_pattern: input tfrecord file pattern.\n",
        "      tf_transform_output: A TFTransformOutput.\n",
        "      batch_size: representing the number of consecutive elements of returned\n",
        "        dataset to combine in a single batch\n",
        "\n",
        "    Returns:\n",
        "      A dataset that contains (features, indices) tuple where features is a\n",
        "        dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "    \"\"\"\n",
        "    transformed_feature_spec = (\n",
        "        tf_transform_output.transformed_feature_spec().copy())\n",
        "\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        features=transformed_feature_spec,\n",
        "        reader=_gzip_reader_fn,\n",
        "        label_key=LABEL_KEY)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: TrainerFnArgs):\n",
        "    \"\"\"Train the model based on given args.\n",
        "\n",
        "    Args:\n",
        "      fn_args: Holds args used to train the model as name/value pairs.\n",
        "    \"\"\"\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "    train_dataset = _input_fn(fn_args.train_files, tf_transform_output, 32)\n",
        "    eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output, 32)\n",
        "\n",
        "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "    with mirrored_strategy.scope():\n",
        "        model = get_model(tf_transform_output=tf_transform_output)\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        steps_per_epoch=fn_args.train_steps,\n",
        "        validation_data=eval_dataset,\n",
        "        validation_steps=fn_args.eval_steps)\n",
        "\n",
        "    signatures = {\n",
        "        'serving_default':\n",
        "            _get_serve_tf_examples_fn(model,\n",
        "                                      tf_transform_output).get_concrete_function(\n",
        "                                          tf.TensorSpec(\n",
        "                                              shape=[None],\n",
        "                                              dtype=tf.string,\n",
        "                                              name='examples')),\n",
        "    }\n",
        "    model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4n7fkCbnvHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "2664b6fe-0c44-482a-9a38-a199ecc0502a"
      },
      "source": [
        "# NOTE: Adjust the number of training and evaluation steps\n",
        "TRAINING_STEPS = 10000\n",
        "EVALUATION_STEPS = 1000\n",
        "\n",
        "trainer = Trainer(\n",
        "    module_file=os.path.abspath(\"trainer.py\"),\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    train_args=trainer_pb2.TrainArgs(num_steps=TRAINING_STEPS),\n",
        "    eval_args=trainer_pb2.EvalArgs(num_steps=EVALUATION_STEPS))\n",
        "context.run(trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD2kK5XQenDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "9e12b9dc-54d7-478f-c56a-c0921c6593a0"
      },
      "source": [
        "model_resolver = ResolverNode(\n",
        "    instance_name='latest_blessed_model_resolver',\n",
        "    resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
        "    model=Channel(type=Model),\n",
        "    model_blessing=Channel(type=ModelBlessing))\n",
        "\n",
        "context.run(model_resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgH50dYW5C2T",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVOPbS9Te6MW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "deb779f6-bae9-4bff-d9f4-ccb6c71e3b04"
      },
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        tfma.ModelSpec(label_key='label')\n",
        "    ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount')\n",
        "            ],\n",
        "            thresholds = {\n",
        "                'binary_accuracy': tfma.MetricThreshold(\n",
        "                    value_threshold=tfma.GenericValueThreshold(\n",
        "                        lower_bound={'value': 0.5}),\n",
        "                    change_threshold=tfma.GenericChangeThreshold(\n",
        "                       direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                       absolute={'value': -1e-10}))\n",
        "            }\n",
        "        )\n",
        "    ],\n",
        "    slicing_specs=[\n",
        "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "        tfma.SlicingSpec(),\n",
        "    ])\n",
        "\n",
        "evaluator = Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    baseline_model=model_resolver.outputs['model'],\n",
        "    eval_config=eval_config\n",
        ")\n",
        "\n",
        "context.run(evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD3Q8gnznAnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c61d013-8143-4d66-cbf6-ff3c902c8480"
      },
      "source": [
        "# Check the blessing\n",
        "!ls {evaluator.outputs['blessing'].get()[0].uri}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f4Z0vJWOIyk",
        "colab_type": "text"
      },
      "source": [
        "## Model Export for Serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxxXrsdebY63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "0f8a9cb0-d42b-43ef-83e8-cb72c0d3d9b1"
      },
      "source": [
        "!mkdir /content/serving_model_dir\n",
        "\n",
        "serving_model_dir = \"/content/serving_model_dir\"\n",
        "\n",
        "pusher = Pusher(\n",
        "    model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=pusher_pb2.PushDestination(\n",
        "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "            base_directory=serving_model_dir)))\n",
        "\n",
        "context.run(pusher)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWni3fVVafDa",
        "colab_type": "text"
      },
      "source": [
        "## Test your Exported Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTi19Ojrbumq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19de31e3-fc52-457d-f5fd-2b35f7f9c4a7"
      },
      "source": [
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "push_uri = pusher.outputs.model_push.get()[0].uri\n",
        "latest_version = max(os.listdir(push_uri))\n",
        "latest_version_path = os.path.join(push_uri, latest_version)\n",
        "loaded_model = tf.saved_model.load(latest_version_path)\n",
        "\n",
        "example_str = b\"This is the finest show ever produced for TV. Each episode is a triumph. The casting, the writing, the timing are all second to none. This cast performs miracles.\"\n",
        "example = tf.train.Example(features=tf.train.Features(feature={\n",
        "    'text': _bytes_feature(example_str)}))\n",
        "\n",
        "serialized_example = example.SerializeToString()\n",
        "f = loaded_model.signatures[\"serving_default\"]\n",
        "print(f(tf.constant([serialized_example])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK0o5XmGOQFb",
        "colab_type": "text"
      },
      "source": [
        "## Upload the Exported Model to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQtGmOjJmKRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1a48a144-7de8-4511-d9de-f7982a20397f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir /content/drive/My\\ Drive/exported_model\n",
        "!cp -r {pusher.outputs.model_push.get()[0].uri} /content/drive/My\\ Drive/exported_model/\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "print('Exported model has been uploaded to your Google Drive.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "TFX_Pipeline_for_Bert_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}